{"cells":[{"metadata":{"id":"9jEuzC42uZng"},"cell_type":"markdown","source":"# Quantum Transfer Learning\n## Based on Pennylane"},{"metadata":{"id":"00_oy9G2wPgb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677098425777,"user_tz":300,"elapsed":5093,"user":{"displayName":"Saniya Nazeer","userId":"01098363341448420394"}},"outputId":"fe387118-6c4d-4b89-eb65-359b9a81075b","trusted":true},"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/gdrive')","execution_count":2,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jY9B5CBhuZnj","executionInfo":{"status":"ok","timestamp":1677098431832,"user_tz":300,"elapsed":4537,"user":{"displayName":"Saniya Nazeer","userId":"01098363341448420394"}},"outputId":"3fd9ac94-3b94-4157-d96c-6dcf99dc1cec","trusted":true},"cell_type":"code","source":"import time\nimport os\nimport copy\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nfrom torchvision import datasets, transforms\n\n# Pennylane\n!pip install pennylane --upgrade\nimport pennylane as qml\nfrom pennylane import numpy as np\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Plotting\nimport matplotlib.pyplot as plt\n\n# OpenMP: number of parallel threads.\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"","execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-adb2d789c235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"]}]},{"metadata":{"id":"aa8orYxruZnk","trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"id":"YCodDuQiuZnl","trusted":true},"cell_type":"code","source":"n_qubits = 4                # Number of qubits\nstep = 0.0004               # Learning rate\nbatch_size = 4              # Number of samples for each training step\nnum_epochs = 3              # Number of training epochs\nq_depth = 6                 # Depth of the quantum circuit (number of variational layers)\ngamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\nq_delta = 0.01              # Initial spread of random quantum weights\nstart_time = time.time()    # Start of the computation timer","execution_count":null,"outputs":[]},{"metadata":{"id":"47W5tLtzuZnl","trusted":true},"cell_type":"code","source":"data_transforms = {\n    \"train\": transforms.Compose(\n        [\n            # transforms.RandomResizedCrop(224),     # uncomment for data augmentation\n            # transforms.RandomHorizontalFlip(),     # uncomment for data augmentation\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            # Normalize input channels using mean values and standard deviations of ImageNet.\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]\n    ),\n    \"val\": transforms.Compose(\n        [\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]\n    ),\n}\ndata_dir = '_data/Dark-QCD-Data/'\nimage_datasets = {\n    x if x == \"train\" else \"validation\": datasets.ImageFolder(\n        os.path.join(data_dir, x), data_transforms[x]\n    )\n    for x in [\"train\", \"val\"]\n}\ndataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"validation\"]}\nclass_names = image_datasets[\"train\"].classes\n\n# Initialize dataloader\ndataloaders = {\n    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n    for x in [\"train\", \"validation\"]\n}\n\n# function to plot images\ndef imshow(inp, title=None):\n    \"\"\"Display image from tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    # Inverse of the initial normalization operation.\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"id":"A_AJ4g1quZnm","outputId":"9bcc0b17-6d1f-450a-f67b-837b0a36c240","colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"status":"ok","timestamp":1677098446990,"user_tz":300,"elapsed":3090,"user":{"displayName":"Saniya Nazeer","userId":"01098363341448420394"}},"trusted":true},"cell_type":"code","source":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders[\"validation\"]))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])\n\ndataloaders = {\n    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n    for x in [\"train\", \"validation\"]\n}","execution_count":null,"outputs":[]},{"metadata":{"id":"TAToJf7WuZnr","outputId":"79a7e99a-bf62-4c52-ca4d-86a3a3f2958a","colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["5c543ebf90974d9d87b3aed3e5dd6f72","b3756e3aa7004f378cc9d9b52a612a62","76e6f0df1ab848da8780379fb4fb53f2","e330b90e6f4a40c687a4176149622473","508cf7366b0b461db7ad9b6fbc9942c3","54f42927e1b9414f8b035aa0cd72fb2f","23d5f093df1a4f799f98b13a07eb088a","27ae36ecf51f429d80aa28863669d8e0","526f02ecb8f442028f4ff76ce0af30c3","5378221a160e425481c90b0d3d9856e3","7dd5ad1d439d409e85009c840dcbdddd"]},"executionInfo":{"status":"ok","timestamp":1677098465744,"user_tz":300,"elapsed":2105,"user":{"displayName":"Saniya Nazeer","userId":"01098363341448420394"}},"trusted":true},"cell_type":"code","source":"model_hybrid = torchvision.models.resnet18(pretrained=True)\n\nn_qubits = 4\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.AmplitudeEmbedding(features=inputs, wires=range(4), normalize=True)\n    qml.BasicEntanglerLayers(weights, wires=range(4))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\n\nn_layers = 6\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\n\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n\n# Notice that model_hybrid.fc is the last layer of ResNet18\nmodel_hybrid.fc = nn.Sequential(\n    nn.Linear(512, 256),\n    nn.ReLU(),\n    nn.Linear(256, 64),\n    nn.ReLU(),\n    nn.Linear(64, 16),\n    nn.ReLU(),\n    qlayer,\n    nn.ReLU(),\n    nn.Linear(4,2)\n)\n\n# Use CUDA or CPU according to the \"device\" object.\nmodel_hybrid = model_hybrid.to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"lZEtwnLTuZns","trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)\nexp_lr_scheduler = lr_scheduler.StepLR(\n    optimizer_hybrid, step_size=10, gamma=gamma_lr_scheduler\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"_dXwstKkuZns","trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    best_loss = 10000.0  # Large arbitrary number\n    best_acc_train = 0.0\n    best_loss_train = 10000.0  # Large arbitrary number\n    print(\"Training started:\")\n\n    for epoch in range(num_epochs):\n\n        # Each epoch has a training and validation phase\n        for phase in [\"train\", \"validation\"]:\n            if phase == \"train\":\n                # Set model to training mode\n                model.train()\n            else:\n                # Set model to evaluate mode\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            n_batches = dataset_sizes[phase] // batch_size\n            it = 0\n            for inputs, labels in dataloaders[phase]:\n                since_batch = time.time()\n                batch_size_ = len(inputs)\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n\n                # Track/compute gradient and make an optimization step only when training\n                with torch.set_grad_enabled(phase == \"train\"):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    if phase == \"train\":\n                        loss.backward()\n                        optimizer.step()\n\n                # Print iteration results\n                running_loss += loss.item() * batch_size_\n                batch_corrects = torch.sum(preds == labels.data).item()\n                running_corrects += batch_corrects\n                print(\n                    \"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n                        phase,\n                        epoch + 1,\n                        num_epochs,\n                        it + 1,\n                        n_batches + 1,\n                        time.time() - since_batch,\n                    ),\n                    end=\"\\r\",\n                    flush=True,\n                )\n                it += 1\n\n            # Print epoch results\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects / dataset_sizes[phase]\n            print(\n                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n                    \"train\" if phase == \"train\" else \"validation  \",\n                    epoch + 1,\n                    num_epochs,\n                    epoch_loss,\n                    epoch_acc,\n                )\n            )\n\n            # Check if this is the best model wrt previous epochs\n            if phase == \"validation\" and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == \"validation\" and epoch_loss < best_loss:\n                best_loss = epoch_loss\n            if phase == \"train\" and epoch_acc > best_acc_train:\n                best_acc_train = epoch_acc\n            if phase == \"train\" and epoch_loss < best_loss_train:\n                best_loss_train = epoch_loss\n\n            # Update learning rate\n            if phase == \"train\":\n                scheduler.step()\n\n    # Print final results\n    model.load_state_dict(best_model_wts)\n    time_elapsed = time.time() - since\n    print(\n        \"Training completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n    )\n    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"MPSlQyRquZnt","outputId":"519d4aa4-acd8-4cd7-d83d-02e7fb3a6120","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677098904951,"user_tz":300,"elapsed":431100,"user":{"displayName":"Saniya Nazeer","userId":"01098363341448420394"}},"trusted":true},"cell_type":"code","source":"model_hybrid = train_model(\n    model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"ctox8sVWuZnv","trusted":true},"cell_type":"code","source":"def visualize_model(model, num_images=6, fig_name=\"Predictions\"):\n    images_so_far = 0\n    _fig = plt.figure(fig_name)\n    model.eval()\n    with torch.no_grad():\n        for _i, (inputs, labels) in enumerate(dataloaders[\"validation\"]):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images // 2, 2, images_so_far)\n                ax.axis(\"off\")\n                ax.set_title(\"[{}]\".format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n                if images_so_far == num_images:\n                    return","execution_count":null,"outputs":[]},{"metadata":{"id":"BESchD5GuZnv","outputId":"178ed226-918e-410e-f7bc-9cf647de5c38","colab":{"base_uri":"https://localhost:8080/","height":264},"executionInfo":{"status":"ok","timestamp":1677098943785,"user_tz":300,"elapsed":1148,"user":{"displayName":"Saniya Nazeer","userId":"01098363341448420394"}},"trusted":true},"cell_type":"code","source":"visualize_model(model_hybrid, num_images=batch_size)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"ELxlP7MvuZnw","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"8f1908c077c76fe0679220641698397215db9c2f72ea119586416ea3d02c9b38"}},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"5c543ebf90974d9d87b3aed3e5dd6f72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3756e3aa7004f378cc9d9b52a612a62","IPY_MODEL_76e6f0df1ab848da8780379fb4fb53f2","IPY_MODEL_e330b90e6f4a40c687a4176149622473"],"layout":"IPY_MODEL_508cf7366b0b461db7ad9b6fbc9942c3"}},"b3756e3aa7004f378cc9d9b52a612a62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54f42927e1b9414f8b035aa0cd72fb2f","placeholder":"​","style":"IPY_MODEL_23d5f093df1a4f799f98b13a07eb088a","value":"100%"}},"76e6f0df1ab848da8780379fb4fb53f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27ae36ecf51f429d80aa28863669d8e0","max":46830571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_526f02ecb8f442028f4ff76ce0af30c3","value":46830571}},"e330b90e6f4a40c687a4176149622473":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5378221a160e425481c90b0d3d9856e3","placeholder":"​","style":"IPY_MODEL_7dd5ad1d439d409e85009c840dcbdddd","value":" 44.7M/44.7M [00:00&lt;00:00, 47.1MB/s]"}},"508cf7366b0b461db7ad9b6fbc9942c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54f42927e1b9414f8b035aa0cd72fb2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d5f093df1a4f799f98b13a07eb088a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27ae36ecf51f429d80aa28863669d8e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"526f02ecb8f442028f4ff76ce0af30c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5378221a160e425481c90b0d3d9856e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dd5ad1d439d409e85009c840dcbdddd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":1}